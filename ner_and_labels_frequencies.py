# -*- coding: utf-8 -*-
"""NER and labels frequencies

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/133jp1cz8HAz4VPkUBrYFr9KE7QwldJeF
"""

# This is a code to NER labels from VCR files, and to compose a file with ('Year', 'Entity Text', 'Instances') labels ...
# to find the number of mention of each entity at each year, to create a frequency-based heatmap.

import spacy
import json
import csv
from collections import defaultdict

# Load spaCy model
nlp = spacy.load("en_core_web_sm")

# Load your cleaned JSON data
with open('/content/cleaned_VCRSection10.json') as f:
    textDict = json.load(f)

# Define months
months = ['JANUARY', 'FEBRUARY', 'MARCH', 'APRIL', 'MAY', 'JUNE',
          'JULY', 'AUGUST', 'SEPTEMBER', 'OCTOBER', 'NOVEMBER', 'DECEMBER']

# Labels to keep
valid_labels = {'GPE', 'LOC'}

# Output file paths
entity_output_path = 'entities10.csv'
entity_frequency_output_path = 'entity_frequencies10.csv'

# Track frequencies: year → entity text → count
entity_frequencies = defaultdict(lambda: defaultdict(int))

# Last known year
prev_year = None

# Write per-page entity details
with open(entity_output_path, 'w', newline='', encoding='utf-8') as entity_csv:
    entity_writer = csv.writer(entity_csv)
    entity_writer.writerow(['PAGE NUMBER', 'Year', 'ENTITY NAME', 'POSITION', 'LABEL'])

    for page_num in textDict.keys():
        text = textDict[page_num]
        lines = text.splitlines()
        first_line = lines[0].strip() if lines else ""
        words = first_line.split()

        # Determine year
        year = prev_year
        if words and words[0].upper() in months:
            parts = first_line.split(',')
            if len(parts) >= 2:
                year_candidate = parts[1].strip()[:4]
                if year_candidate.isdigit():
                    year = year_candidate
                    prev_year = year

        # Extract GPE/LOC entities only
        doc = nlp(text)
        for ent in doc.ents:
            if ent.label_ in valid_labels:
                entity_writer.writerow([page_num, year or "Unknown", ent.text,
                                        f"{ent.start_char}-{ent.end_char}", ent.label_])
                if year:
                    entity_frequencies[year][ent.text] += 1

# Write entity frequencies per year
with open(entity_frequency_output_path, 'w', newline='', encoding='utf-8') as freq_csv:
    freq_writer = csv.writer(freq_csv)
    freq_writer.writerow(['Year', 'Entity Text', 'Instances'])
    for year, text_counts in entity_frequencies.items():
        for text, count in text_counts.items():
            freq_writer.writerow([year, text, count])