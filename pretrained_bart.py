# -*- coding: utf-8 -*-
"""Pretrained_BART.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LWqelsIOKr9-1JhxrVVaI-NjX0vv545z
"""

from transformers import BartTokenizer, BartForConditionalGeneration
import json


tokenizer = BartTokenizer.from_pretrained("facebook/bart-large")
#model = BartForConditionalGeneration.from_pretrained("facebook/bart-large")

with open("/content/Vol1StoreOCRPerPage.json") as f:
   vol1 = json.load(f) #store contents of Vol 1 in dictionary vol1


textsToClean = [vol1[str(k)] for k in range(583, 588)] # Choosing pages in a list

# Create a json file for textsToClean
textsToClean_dict = {str(k): vol1[str(k)] for k in range(583, 589)}
with open("/content/TextsToClean_583to587.json", "w") as f:
    json.dump(textsToClean_dict, f, indent=2)

# clean textsToClean and save cleanedTexts in dict.json file
cleanedTexts = {}
for key, text in textsToClean_dict.items():
    inputs = tokenizer(text, return_tensors="pt", max_length=2048, truncation=True, padding=True)
    # You can use the model here instead decoding  immediately
    cleanText = tokenizer.decode(inputs["input_ids"][0], skip_special_tokens=True).replace('\xa0', ' '). replace('-','')
    cleanedTexts[key] = cleanText

for key in map(str, range(583, 589)):
    print(f"{key}:", cleanedTexts[key])